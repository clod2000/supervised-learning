{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shbM3zJAuPI9"
   },
   "source": [
    "In this lab you will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolution Neural Network\n",
    "3. Define a loss function and optimizer\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "Using ``torchvision``, itâ€™s extremely easy to load CIFAR10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qf9I_7NdzTf6"
   },
   "source": [
    "How to install a different version of a package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S4ZhoQ3vuPI_",
    "ExecuteTime": {
     "end_time": "2024-04-15T22:19:53.966111Z",
     "start_time": "2024-04-15T22:19:52.589109Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6F0vCe0kzcJ9"
   },
   "source": [
    "Use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5bun1lQdwoqy",
    "ExecuteTime": {
     "end_time": "2024-04-15T22:19:54.027640Z",
     "start_time": "2024-04-15T22:19:53.967166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZyKEHctuPI_"
   },
   "source": [
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "   \n",
    "The output of [torchvision datasets](https://pytorch.org/vision/stable/datasets.html#datasets) are PILImage images of range [0, 1].\n",
    "We [transform](https://pytorch.org/vision/stable/transforms.html) them to normalized Tensors. Then we call the [dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nV92dK3ruPI_",
    "ExecuteTime": {
     "end_time": "2024-04-15T22:19:55.439739Z",
     "start_time": "2024-04-15T22:19:54.029560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Define data transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    # Convert PIL images to PyTorch tensors\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize pixel values\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 training dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "# Create data loader for training data with batch size 4 and shuffling\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Load the CIFAR-10 testing dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "# Create data loader for testing data with batch size 1 and shuffling\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "# Define class labels for CIFAR-10 dataset\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nB4FDsouPJA"
   },
   "source": [
    "Let us [show](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib-pyplot-imshow) some of the training images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KVCb2s_QuPJA",
    "ExecuteTime": {
     "end_time": "2024-04-15T22:19:55.973676Z",
     "start_time": "2024-04-15T22:19:55.441033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "12500\n",
      "{'frog': 5000, 'truck': 5000, 'deer': 5000, 'car': 5000, 'bird': 5000, 'horse': 5000, 'ship': 5000, 'cat': 5000, 'dog': 5000, 'plane': 5000}\n",
      "torch.Size([4, 3, 32, 32])\n",
      "car cat dog deer\n",
      "\n",
      "Test loader:\n",
      "10000\n",
      "{'cat': 1000, 'ship': 1000, 'plane': 1000, 'frog': 1000, 'car': 1000, 'truck': 1000, 'dog': 1000, 'horse': 1000, 'deer': 1000, 'bird': 1000}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # Import library for plotting\n",
    "import numpy as np  # Import library for numerical computations\n",
    "from collections import Counter  # Import Counter for counting elements\n",
    "\n",
    "# Function to display an image\n",
    "def imshow(image):\n",
    "    mean=torch.tensor([0.485, 0.456, 0.406])\n",
    "    std=torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "    # Unnormalize the image channels to [0, 1]\n",
    "    image = image.mul(std.unsqueeze(1).unsqueeze(2))  # More efficient element-wise multiplication\n",
    "    image = image.add(mean.unsqueeze(1).unsqueeze(2))  # Efficient element-wise addition\n",
    "\n",
    "    image= image.clamp(0, 1)\n",
    "\n",
    "    # Convert the tensor to a NumPy array\n",
    "    npimg = image.numpy()\n",
    "    # Plot the image using matplotlib\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # Transpose for correct display\n",
    "\n",
    "# ------------------ Train Loader Section ------------------\n",
    "\n",
    "print(\"Train loader:\")\n",
    "\n",
    "# Count the frequency of each class in the training set\n",
    "stat = dict(Counter(trainset.targets))\n",
    "\n",
    "# Create a new dictionary with class names as keys\n",
    "new_stat = stat.copy()\n",
    "for k in stat.keys():\n",
    "    new_stat[classes[k]] = stat[k]\n",
    "    del new_stat[k]\n",
    "\n",
    "# Print the length of the train loader (number of batches)\n",
    "print(len(trainloader))\n",
    "\n",
    "# Print the class distribution in the training set\n",
    "print(new_stat)\n",
    "\n",
    "# Get a batch of random training images and their labels\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Print the shape of the image tensor (batch_size, channels, height, width)\n",
    "print(images.shape)\n",
    "\n",
    "# Display the images using the imshow function\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# Print the labels of the images\n",
    "print(' '.join('%s' % classes[labels[j]] for j in range(4)))  # Print labels for 4 images\n",
    "\n",
    "# ------------------ Test Loader Section ------------------\n",
    "\n",
    "print(\"\\nTest loader:\")\n",
    "\n",
    "# Similar steps for the test loader\n",
    "stat = dict(Counter(testset.targets))\n",
    "new_stat = stat.copy()\n",
    "for k in stat.keys():\n",
    "    new_stat[classes[k]] = stat[k]\n",
    "    del new_stat[k]\n",
    "\n",
    "print(len(testloader))\n",
    "print(new_stat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWjfTuThuPJA"
   },
   "source": [
    "2. Define a Convolution Neural Network.\n",
    "[network layers](https://pytorch.org/docs/stable/nn.html#convolution-layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8HW6XRf7uPJB",
    "ExecuteTime": {
     "end_time": "2024-04-15T22:19:56.081108Z",
     "start_time": "2024-04-15T22:19:55.974913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Net(\n  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    This class defines a simple convolutional neural network (CNN) architecture\n",
    "    for image classification.\n",
    "\n",
    "    Attributes:\n",
    "        conv1 (nn.Conv2d): First convolutional layer with 3 input channels (RGB),\n",
    "                           6 output channels, and a kernel size of 5x5.\n",
    "        pool (nn.MaxPool2d): Max pooling layer with a kernel size of 2x2.\n",
    "        conv2 (nn.Conv2d): Second convolutional layer with 6 input channels\n",
    "                           (from the first conv layer), 16 output channels,\n",
    "                           and a kernel size of 5x5.\n",
    "        fc1 (nn.Linear): First fully-connected layer that flattens the input\n",
    "                         from the previous convolutional layers and has 120 neurons.\n",
    "        fc2 (nn.Linear): Second fully-connected layer with 84 neurons.\n",
    "        fc3 (nn.Linear): Output layer with 10 neurons, corresponding to the 10 classes\n",
    "                         in CIFAR-10.\n",
    "\n",
    "    Methods:\n",
    "        forward(self, x): Defines the forward pass of the network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()  # Call the superclass constructor\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  # First convolutional layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Max pooling layer\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  # Second convolutional layer\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # First fully-connected layer\n",
    "        self.fc2 = nn.Linear(120, 84)  # Second fully-connected layer\n",
    "        self.fc3 = nn.Linear(84, 10)  # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the neural network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor representing the images.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor representing the class probabilities.\n",
    "        \"\"\"\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # First convolutional layer with ReLU activation and pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Second convolutional layer with ReLU activation and pooling\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.shape[0],-1)  # Flatten the output from convolutional layers\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc1(x))  # First fully-connected layer with ReLU activation\n",
    "        x = F.relu(self.fc2(x))  # Second fully-connected layer with ReLU activation\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute the receptive field of the network"
   ],
   "metadata": {
    "id": "O2P0Zlbl2Stb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# This line attempts to clone a Git repository using a shell command.\n",
    "!git clone https://github.com/Fangyh09/pytorch-receptive-field.git\n",
    "\n",
    "# This line would move the downloaded directory\n",
    "!mv -v pytorch-receptive-field/torch_receptive_field ./\n",
    "\n",
    "# Import the 'receptive_field' function from the 'torch_receptive_field' library.\n",
    "from torch_receptive_field import receptive_field\n",
    "\n",
    "# Calculate the receptive field of the network 'net' for an input image size of\n",
    "# 3 channels (RGB) and 32x32 pixels. The 'receptive_field' function would analyze the network architecture and input size to determine\n",
    "# the receptive field size for each layer and the overall network.\n",
    "receptive_field(net, input_size=(3, 32, 32))\n"
   ],
   "metadata": {
    "id": "tsX3Q7q32SgF",
    "ExecuteTime": {
     "end_time": "2024-04-15T22:19:56.706674Z",
     "start_time": "2024-04-15T22:19:56.081970Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pytorch-receptive-field' already exists and is not an empty directory.\r\n",
      "mv: cannot stat 'pytorch-receptive-field/torch_receptive_field': No such file or directory\r\n",
      "------------------------------------------------------------------------------\n",
      "        Layer (type)    map size      start       jump receptive_field \n",
      "==============================================================================\n",
      "        0               [32, 32]        0.5        1.0             1.0 \n",
      "        1               [28, 28]        2.5        1.0             5.0 \n",
      "        2               [14, 14]        3.0        2.0             6.0 \n",
      "        3               [10, 10]        7.0        2.0            14.0 \n",
      "        4                 [5, 5]        8.0        4.0            16.0 \n",
      "==============================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "OrderedDict([('0',\n              OrderedDict([('j', 1.0),\n                           ('r', 1.0),\n                           ('start', 0.5),\n                           ('conv_stage', True),\n                           ('output_shape', [-1, 3, 32, 32])])),\n             ('1',\n              OrderedDict([('j', 1.0),\n                           ('r', 5.0),\n                           ('start', 2.5),\n                           ('input_shape', [-1, 3, 32, 32]),\n                           ('output_shape', [-1, 6, 28, 28])])),\n             ('2',\n              OrderedDict([('j', 2.0),\n                           ('r', 6.0),\n                           ('start', 3.0),\n                           ('input_shape', [-1, 6, 28, 28]),\n                           ('output_shape', [-1, 6, 14, 14])])),\n             ('3',\n              OrderedDict([('j', 2.0),\n                           ('r', 14.0),\n                           ('start', 7.0),\n                           ('input_shape', [-1, 6, 14, 14]),\n                           ('output_shape', [-1, 16, 10, 10])])),\n             ('4',\n              OrderedDict([('j', 4.0),\n                           ('r', 16.0),\n                           ('start', 8.0),\n                           ('input_shape', [-1, 16, 10, 10]),\n                           ('output_shape', [-1, 16, 5, 5])])),\n             ('input_size', (3, 32, 32))])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmA4DkACuPJB"
   },
   "source": [
    "3. Define a loss function and optimizer\n",
    "\n",
    "Let's use a Classification [Cross-Entropy](https://pytorch.org/docs/stable/nn.html#loss-functions) loss and [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD) with momentum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yl7S3NpruPJB",
    "ExecuteTime": {
     "end_time": "2024-04-15T22:19:56.710792Z",
     "start_time": "2024-04-15T22:19:56.707547Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim  # Import the optim module from PyTorch for optimization algorithms\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()  # Use cross-entropy loss for multi-class classification\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Explanation of the optimizer:\n",
    "#   - optim.SGD(net.parameters(), lr=0.001, momentum=0.9):\n",
    "#       - optim.SGD: This selects the Stochastic Gradient Descent (SGD) optimizer.\n",
    "#       - net.parameters(): This provides the parameters of the network (`net`) to be optimized.\n",
    "#       - lr=0.001: This sets the learning rate to 0.001 (controls how much the weights are updated).\n",
    "#       - momentum=0.9: This sets the momentum to 0.9 (a technique to improve convergence).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmu1-dvfuPJB"
   },
   "source": [
    "4. Train the network on the training data\n",
    "\n",
    "\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "928O4nWYuPJC",
    "ExecuteTime": {
     "end_time": "2024-04-15T22:19:59.443513Z",
     "start_time": "2024-04-15T22:19:56.711932Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 28\u001B[0m\n\u001B[1;32m     26\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)  \u001B[38;5;66;03m# Compute the loss based on the predictions (outputs) and ground truth labels\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# 3. Backward pass:\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()  \u001B[38;5;66;03m# Backpropagate the loss to calculate gradients for each parameter in the network\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# 4. Optimization step:\u001B[39;00m\n\u001B[1;32m     30\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()  \u001B[38;5;66;03m# Update the weights and biases of the network based on the calculated gradients\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/torch/_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    521\u001B[0m     )\n\u001B[0;32m--> 522\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[1;32m    523\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[1;32m    524\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 266\u001B[0m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    267\u001B[0m     tensors,\n\u001B[1;32m    268\u001B[0m     grad_tensors_,\n\u001B[1;32m    269\u001B[0m     retain_graph,\n\u001B[1;32m    270\u001B[0m     create_graph,\n\u001B[1;32m    271\u001B[0m     inputs,\n\u001B[1;32m    272\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    273\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    274\u001B[0m )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "num_print_intervals = 4  # Number of times to print statistics\n",
    "\n",
    "num_print_intervals+=1\n",
    "print_interval = int(len(trainloader) / num_print_intervals)\n",
    "\n",
    "# Loop over the dataset multiple times (2 epochs in this case)\n",
    "for epoch in range(2):\n",
    "    running_loss=[]  # Initialize a variable to track the total loss for this epoch\n",
    "\n",
    "    # Iterate over the training data loader\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs (images) and labels from the current batch\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Move the inputs and labels to the specified device (CPU or GPU)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear the gradients accumulated in the previous iteration\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Training loop: forward pass, backward pass, and optimization\n",
    "        # 1. Forward pass:\n",
    "        outputs = net(inputs)  # Pass the input images through the network to get predictions (outputs)\n",
    "        # 2. Calculate loss:\n",
    "        loss = criterion(outputs, labels)  # Compute the loss based on the predictions (outputs) and ground truth labels\n",
    "        # 3. Backward pass:\n",
    "        loss.backward()  # Backpropagate the loss to calculate gradients for each parameter in the network\n",
    "        # 4. Optimization step:\n",
    "        optimizer.step()  # Update the weights and biases of the network based on the calculated gradients\n",
    "\n",
    "        running_loss.append(loss.item())  # Accumulate the loss for this mini-batch\n",
    "        if i>0 and i % print_interval == 0:  # Check batch interval\n",
    "            # Print the average loss for the mini-batches\n",
    "            print('[%d, %5d] loss: %.4f' %\n",
    "                  (epoch + 1, i + 1, np.mean(running_loss)))\n",
    "            # Reset the running loss for the next interval\n",
    "            running_loss=[]\n",
    "\n",
    "# Training complete\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzpMI9aUuPJC"
   },
   "source": [
    "5. Test the network on the test data\n",
    "\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.\n",
    "But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_JnNda2uPJD"
   },
   "outputs": [],
   "source": [
    "# Initialize variables to track accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Disable gradient calculation for better performance during evaluation\n",
    "with torch.no_grad():\n",
    "    # Loop over the test loader\n",
    "    for data in testloader:\n",
    "        # Get the image and label from the current batch\n",
    "        image, label = data\n",
    "\n",
    "        # Move the image data to the specified device (CPU or GPU)\n",
    "        image = image.to(device)\n",
    "\n",
    "        # Get the network's prediction for the image\n",
    "        output = net(image)\n",
    "        # smax = torch.nn.Softmax(dim=1)(output.cpu())\n",
    "\n",
    "        # Find the class with the highest probability\n",
    "        _, predicted = torch.max(output.cpu(), 1)  # Equivalent to pred = torch.argmax(output.cpu(), dim=1)\n",
    "\n",
    "        # Update total number of test images\n",
    "        total += label.size(0)  # label.size(0) gives the batch size\n",
    "\n",
    "        # Count correct predictions\n",
    "        correct += (predicted == label).sum().item()  # Count true positives\n",
    "\n",
    "# Calculate and print accuracy\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1Y4HMBOxCE6"
   },
   "source": [
    "**!HOMEWORK!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZW_s0fsB1Xi"
   },
   "source": [
    "This homework assignment asks you to performs 2 tasks:\n",
    "\n",
    "1. Analyze Results with Different Network Parameters:\n",
    "\n",
    "This involves training the network with various configurations of network parameters and analyzing the impact on performance. Here's a step-by-step approach:\n",
    "\n",
    "**Choose Network Parameters:**\n",
    "\n",
    "Select the network parameters you want to experiment with. Common choices include:\n",
    "\n",
    "Number of layers: You can try increasing or decreasing the number of layers in your chosen network architecture (e.g., convolutional layers in a CNN).\n",
    "Learning rate: Experiment with different learning rates (e.g., 0.01, 0.001, 0.0001) to find a balance between fast learning and stability.\n",
    "Other parameters: Depending on your network architecture, there might be additional options like:\n",
    "Number of filters in convolutional layers: This affects the complexity of features extracted from the data.\n",
    "Activation functions: Experiment with different activation functions (e.g., ReLU, Leaky ReLU) to introduce non-linearity.\n",
    "Optimizer parameters: Some optimizers (e.g., Adam) have hyperparameters you can adjust.\n",
    "Train the network for a different number of epochs.\n",
    "\n",
    "**Analyze Results:**\n",
    "\n",
    "Compare the performance of the network across different parameter configurations:\n",
    "\n",
    "How accuracy/loss changes with different parameter values.\n",
    "2. Show and Explain Errors of the Best Network:\n",
    "\n",
    "Once you identify the **best performing network configuration** (based on metrics like accuracy or loss), analyze its errors.\n",
    "For example you can generate a confusion matrix. This matrix visualizes how often the network predicted each class correctly or incorrectly.\n",
    "\n",
    "Useful resources:\n",
    "*   [network layers](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
    "*   [activation function](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
    "*   [loss functions](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import CNN_lib "
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
